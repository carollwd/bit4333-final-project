{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development for Student Performance Analysis\n",
        "This notebook trains and compares different machine learning models to predict students' performance.\n"
      ],
      "metadata": {
        "id": "To2QwxcNWNM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. IMPORTS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
        "import joblib\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "EnUuRPdckvgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LOAD DATA\n",
        "uploaded_files = files.upload()\n",
        "df = pd.read_csv(list(uploaded_files.keys())[0])\n",
        "print(\"Data preview:\\n\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "R3YWEfpqk1MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. CREATE GRADE CATEGORY IF MISSING\n",
        "if 'GradeCategory' not in df.columns:\n",
        "    def score_to_grade(score):\n",
        "        if score >= 90: return 'A+'\n",
        "        elif score >= 80: return 'A'\n",
        "        elif score >= 70: return 'B'\n",
        "        elif score >= 60: return 'C'\n",
        "        else: return 'D'\n",
        "    df['GradeCategory'] = df['Exam_Score'].apply(score_to_grade)\n",
        "    print(\"GradeCategory column created from Exam_Score.\")"
      ],
      "metadata": {
        "id": "O2DAobB9k1JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. FEATURE / TARGET SPLIT\n",
        "X = df.drop(columns=['Exam_Score', 'GradeCategory'])\n",
        "y_reg = df['Exam_Score']\n",
        "y_clf = df['GradeCategory']"
      ],
      "metadata": {
        "id": "XbmRNYAwk1HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. ENCODE CATEGORICAL FEATURES\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Encode classification target\n",
        "le = LabelEncoder()\n",
        "y_clf_enc = le.fit_transform(y_clf)"
      ],
      "metadata": {
        "id": "UwKI5V6jk1Es"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. TRAIN-TEST SPLIT\n",
        "# Regression\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_encoded, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Classification\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
        "    X_encoded, y_clf_enc, test_size=0.2, random_state=42, stratify=y_clf_enc\n",
        ")"
      ],
      "metadata": {
        "id": "eew0lJp0k1Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. FEATURE SCALING\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reg)\n",
        "X_test_scaled = scaler.transform(X_test_reg)\n",
        "X_train_scaled_clf = scaler.fit_transform(X_train_clf)\n",
        "X_test_scaled_clf = scaler.transform(X_test_clf)"
      ],
      "metadata": {
        "id": "rzdK4NUIk1Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. DEFINE MODELS\n",
        "# Regression models\n",
        "reg_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'SVR': SVR(),\n",
        "    'XGBoost': XGBRegressor(eval_metric='rmse', use_label_encoder=False),\n",
        "    'CatBoost': CatBoostRegressor(verbose=0)\n",
        "}\n",
        "\n",
        "# Classification models\n",
        "clf_models = {\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0)\n",
        "}"
      ],
      "metadata": {
        "id": "LeBI3iadk033"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. TRAIN MODELS & STORE RESULTS\n",
        "reg_results = []\n",
        "for name, model in reg_models.items():\n",
        "    model.fit(X_train_scaled, y_train_reg)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mse = mean_squared_error(y_test_reg, y_pred)\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "    reg_results.append({'Model': name, 'MSE': mse, 'R2': r2})\n",
        "reg_df = pd.DataFrame(reg_results)\n",
        "\n",
        "clf_results = []\n",
        "for name, model in clf_models.items():\n",
        "    model.fit(X_train_scaled_clf, y_train_clf)\n",
        "    y_pred = model.predict(X_test_scaled_clf)\n",
        "    acc = accuracy_score(y_test_clf, y_pred)\n",
        "    f1 = f1_score(y_test_clf, y_pred, average='weighted')\n",
        "    clf_results.append({'Model': name, 'Accuracy': acc, 'F1': f1})\n",
        "clf_df = pd.DataFrame(clf_results)"
      ],
      "metadata": {
        "id": "x2-TXxMxk0z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. SELECT BEST MODELS & SAVE\n",
        "# Regression\n",
        "best_reg_model_name = reg_df.sort_values('MSE').iloc[0]['Model']\n",
        "best_reg_model = reg_models[best_reg_model_name]\n",
        "joblib.dump(best_reg_model, 'best_reg_model.pkl')\n",
        "files.download('best_reg_model.pkl')\n",
        "\n",
        "# Classification\n",
        "best_clf_model_name = clf_df.sort_values('Accuracy', ascending=False).iloc[0]['Model']\n",
        "best_clf_model = clf_models[best_clf_model_name]\n",
        "joblib.dump(best_clf_model, 'best_clf_model.pkl')\n",
        "files.download('best_clf_model.pkl')"
      ],
      "metadata": {
        "id": "v4ryEEnyk0rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. SHOW RESULTS\n",
        "print(\"=== REGRESSION RESULTS ===\")\n",
        "print(reg_df)\n",
        "print(f\"Best regression model saved: {best_reg_model_name}\")\n",
        "\n",
        "print(\"=== CLASSIFICATION RESULTS ===\")\n",
        "print(clf_df)\n",
        "print(f\"Best classification model saved: {best_clf_model_name}\")"
      ],
      "metadata": {
        "id": "1UOTE4Gfk0hz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}